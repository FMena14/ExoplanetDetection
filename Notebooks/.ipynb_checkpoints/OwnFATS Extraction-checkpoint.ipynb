{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "koi_light_curves_full.npy  koi_light_curves_model_full.npy  README.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../Processed_Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kepler_dataset.csv     koi_metadata.csv  OwnFats\r\n",
      "kepler_downloaded.txt  koi_sets.csv\t README.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../Datos/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: the feature Beyond1Std could not be calculated because ['magnitude', 'error'] are needed.\n",
      "Warning: the feature CAR_mean could not be calculated because ['magnitude', 'time', 'error'] are needed.\n",
      "Warning: the feature CAR_sigma could not be calculated because ['magnitude', 'time', 'error'] are needed.\n",
      "Warning: the feature CAR_tau could not be calculated because ['magnitude', 'time', 'error'] are needed.\n",
      "Warning: the feature Color could not be calculated because ['magnitude', 'time', 'magnitude2'] are needed.\n",
      "Warning: the feature Eta_color could not be calculated because ['magnitude', 'time', 'magnitude2'] are needed.\n",
      "Warning: the feature Q31_color could not be calculated because ['magnitude', 'time', 'magnitude2'] are needed.\n",
      "Warning: the feature StetsonJ could not be calculated because ['magnitude', 'time', 'error', 'magnitude2', 'error2'] are needed.\n",
      "Warning: the feature StetsonK could not be calculated because ['magnitude', 'error'] are needed.\n",
      "Warning: the feature StetsonL could not be calculated because ['magnitude', 'time', 'error', 'magnitude2', 'error2'] are needed.\n",
      "Termino en 12.516811 segundos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Amplitude': 0.47528001055681457,\n",
       " 'AndersonDarling': 1.0,\n",
       " 'Autocor_length': 1.0,\n",
       " 'Con': 0.0,\n",
       " 'Eta_e': 1.9737367290234138,\n",
       " 'FluxPercentileRatioMid20': 0.22316396701247973,\n",
       " 'FluxPercentileRatioMid35': 0.37293943827141829,\n",
       " 'FluxPercentileRatioMid50': 0.53216329552147645,\n",
       " 'FluxPercentileRatioMid65': 0.7092926584782373,\n",
       " 'FluxPercentileRatioMid80': 0.88565351992636576,\n",
       " 'Freq1_harmonics_amplitude_0': 0.028910907649750524,\n",
       " 'Freq1_harmonics_amplitude_1': 0.0081067897076466874,\n",
       " 'Freq1_harmonics_amplitude_2': 0.0072152260786718632,\n",
       " 'Freq1_harmonics_amplitude_3': 0.0048802292586874046,\n",
       " 'Freq1_harmonics_rel_phase_0': 0.0,\n",
       " 'Freq1_harmonics_rel_phase_1': -0.47610252076985216,\n",
       " 'Freq1_harmonics_rel_phase_2': -1.20288479104943,\n",
       " 'Freq1_harmonics_rel_phase_3': 1.0603130320323844,\n",
       " 'Freq2_harmonics_amplitude_0': 0.028601910690315983,\n",
       " 'Freq2_harmonics_amplitude_1': 0.0083295212319006544,\n",
       " 'Freq2_harmonics_amplitude_2': 0.0060294940526573644,\n",
       " 'Freq2_harmonics_amplitude_3': 0.0019914504075881265,\n",
       " 'Freq2_harmonics_rel_phase_0': 0.0,\n",
       " 'Freq2_harmonics_rel_phase_1': 1.4924142464349164,\n",
       " 'Freq2_harmonics_rel_phase_2': 0.61605804518311058,\n",
       " 'Freq2_harmonics_rel_phase_3': 0.61102590714961491,\n",
       " 'Freq3_harmonics_amplitude_0': 0.02834915829935087,\n",
       " 'Freq3_harmonics_amplitude_1': 0.0090738189993907342,\n",
       " 'Freq3_harmonics_amplitude_2': 0.0099564785523166867,\n",
       " 'Freq3_harmonics_amplitude_3': 0.0035277857686741199,\n",
       " 'Freq3_harmonics_rel_phase_0': 0.0,\n",
       " 'Freq3_harmonics_rel_phase_1': 0.89479311561528885,\n",
       " 'Freq3_harmonics_rel_phase_2': 2.5783750843319644,\n",
       " 'Freq3_harmonics_rel_phase_3': 2.2677363615798449,\n",
       " 'LinearTrend': -8.7885327883300622e-06,\n",
       " 'MaxSlope': 0.99264480105881792,\n",
       " 'Mean': 0.5029743491724995,\n",
       " 'Meanvariance': 0.57057284359847193,\n",
       " 'MedianAbsDev': 0.24312546082189224,\n",
       " 'MedianBRP': 0.19800000000000001,\n",
       " 'PairSlopeTrend': 0.10000000000000001,\n",
       " 'PercentAmplitude': 0.99885903376284635,\n",
       " 'PercentDifferenceFluxPercentile': 1.8111289337954979,\n",
       " 'Q31': 0.48230969631630599,\n",
       " 'Rcs': 0.031176431327318798,\n",
       " 'Skew': -0.00071369333579923493,\n",
       " 'SmallKurtosis': -1.1609760599301646,\n",
       " 'Std': 0.28698350466444378}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import FATS\n",
    "\n",
    "time_ex = np.arange(3000)\n",
    "magnitude_ex = np.random.rand(3000)\n",
    "\n",
    "lc_example = np.array([magnitude_ex, time_ex])\n",
    "\n",
    "time_start = time.time()\n",
    "#a = FATS.FeatureSpace(Data=['magnitude','time'],excludeList= ['SlottedA_length','PeriodLS','StetsonK_AC',\"Period_fit\",\"Psi_CS\",\"Psi_eta\"])\n",
    "#SACAR DE EXCLUDE PERIODLS\n",
    "a = a.calculateFeature(lc_example)\n",
    "print(\"Termino en %f segundos\"%(time.time()-time_start))\n",
    "a.result(method='dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Caracteristicas: ', 48)\n"
     ]
    }
   ],
   "source": [
    "features = a.result(method='dict').keys()\n",
    "print(\"Caracteristicas: \",len(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OWN FATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def amplitude(magnitudes):\n",
    "    return 0.5 * (np.max(magnitudes) - np.min(magnitudes))\n",
    "\n",
    "def median_absolute_deviation(magnitudes):\n",
    "    median = np.median(magnitudes)\n",
    "    deviations = magnitudes - median\n",
    "    absolute_deviations = np.absolute(deviations)\n",
    "\n",
    "    return np.median(absolute_deviations)\n",
    "\n",
    "def residual_bright_faint_ratio(magnitudes):    # median as a fit\n",
    "    mean = np.mean(magnitudes)\n",
    "\n",
    "    brighter = magnitudes[magnitudes > mean]\n",
    "    fainter = magnitudes[magnitudes < mean]\n",
    "\n",
    "    resid_brighter = np.mean(np.square(brighter - mean))\n",
    "    resid_fainter = np.mean(np.square(fainter - mean))\n",
    "\n",
    "    ratio = resid_fainter / resid_brighter\n",
    "\n",
    "    return ratio\n",
    "\n",
    "def own_fats(sequence):\n",
    "    time_ex =  np.arange(len(sequence))\n",
    "\n",
    "    minim=np.min(sequence)\n",
    "    maxim = np.max(sequence)\n",
    "    mean = np.mean(sequence)\n",
    "    std = np.std(sequence)\n",
    "    iqr = stats.iqr(sequence) #q31\n",
    "    skew = stats.skew(sequence)\n",
    "    kurt = stats.kurtosis(sequence)\n",
    "    q1 = np.percentile(sequence, 25)\n",
    "    q2 = np.percentile(sequence, 50)\n",
    "    model = LinearRegression(normalize=True,n_jobs=-1)\n",
    "    model.fit(time_ex.reshape(-1,1),sequence)\n",
    "    slope = model.coef_[0]\n",
    "    #new features\n",
    "    ampl = amplitude(sequence)\n",
    "    mad = median_absolute_deviation(sequence)\n",
    "    br_fa = residual_bright_faint_ratio(sequence)\n",
    "    median = np.median(sequence)\n",
    "    return np.array([minim,maxim,mean,std,iqr,skew,kurt,q1,q2,slope,ampl,mad,br_fa,median])\n",
    "\n",
    "def metadata_columns(match,array):\n",
    "    #if stellar:\n",
    "    #    df = pd.read_csv('OwnFats/columnas_metadatos_estrella.csv')\n",
    "    #else:\n",
    "    #    df = pd.read_csv('OwnFats/columnas_metadatos.csv')\n",
    "    df = pd.read_csv(\"../Datos/koi_metadata.csv\")\n",
    "    metadata = df[(df[\"KOI Name\"] == match)].values[0][3:]\n",
    "    return np.hstack((array,metadata))\n",
    "\n",
    "columns_FATS = [\"Minimum\",\"Maximum\",\"Mean\",\"Std\",\"IQR\",\"Skew\",\"Kurtosis\",\"Q1\",\"Q2\",\"Slope\",\"Amplitude\",\"MAD\",\n",
    "               \"Residual Bright Faint Ratio\",\"Median\"]\n",
    "aux = pd.read_csv(\"../Datos/koi_metadata.csv\")\n",
    "columns_metadata = list(aux.columns[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import resample\n",
    "\n",
    "def extract_FATS(X,df_label):\n",
    "    X_fats = []\n",
    "    for sequence,match in zip(X,df_label[\"KOI Name\"]):\n",
    "        aux = own_fats(sequence)\n",
    "        final = metadata_columns(match,aux)\n",
    "        X_fats.append(final)\n",
    "    return np.asarray(X_fats)\n",
    "\n",
    "def save(name_set,features,df_label):\n",
    "    df2save = pd.DataFrame(features,columns=columns_FATS+columns_metadata)\n",
    "    df2save[\"KOI Name\"] = df_label[\"KOI Name\"]\n",
    "    df2save.to_csv(\"../Datos/OwnFats/koi_light_curves_FATS2_metadata_\"+name_set+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read Done!\n"
     ]
    }
   ],
   "source": [
    "df_sets = pd.read_csv(\"../Datos/koi_sets.csv\")\n",
    "mask_train = df_sets[\"Set\"] == \"Train\"\n",
    "mask_test = df_sets[\"Set\"] == \"Test\"\n",
    "mask_unlabeled = df_sets[\"Set\"] == \"Unlabeled\"\n",
    "\n",
    "lc_total = np.load(\"../../Processed_Data/koi_light_curves_full.npy\")\n",
    "lc_train = lc_total[mask_train] \n",
    "lc_test = lc_total[mask_test]\n",
    "lc_unlb =  lc_total[mask_unlabeled]\n",
    "\n",
    "df_label = pd.read_csv(\"../Datos/koi_metadata.csv\")\n",
    "df_label_train = df_label[mask_train] \n",
    "df_label_test = df_label[mask_test]\n",
    "df_label_unlb =  df_label[mask_unlabeled]\n",
    "print(\"Read Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time features = extract_FATS(lc_train,df_label_train) #train\n",
    "save(\"train\",features,df_label_train)\n",
    "print(\"Training already extracted\")\n",
    "\n",
    "%time features = extract_FATS(lc_test,df_label_test) #test\n",
    "save(\"test\",features,df_label_test)\n",
    "print(\"Validation already extracted\")\n",
    "\n",
    "%time features = extract_FATS(lc_unlb,df_label_unlb) #unlb\n",
    "save(\"unlabeled\",features,df_label_unlb)\n",
    "print(\"Candidates already extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
