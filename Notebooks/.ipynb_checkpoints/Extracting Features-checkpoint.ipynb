{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "koi_light_curves_full.npy  koi_light_curves_model_full.npy  README.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../Processed_Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICA\t\t    kepler_downloaded.txt  koi_sets.csv  PCA\r\n",
      "kepler_dataset.csv  koi_metadata.csv\t   OwnFats\t README.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../Datos/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/fmena/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:11: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n",
      "/users/fmena/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:12: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read Done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "df_sets = pd.read_csv(\"../Datos/koi_sets.csv\")\n",
    "mask_train = df_sets[\"Set\"] == \"Train\"\n",
    "mask_test = df_sets[\"Set\"] == \"Test\"\n",
    "\n",
    "lc_total = np.load(\"../../Processed_Data/koi_light_curves_full.npy\") #Raw light curve\n",
    "#lc_total = np.load(\"../../Processed_Data/koi_light_curves_model_full.npy\")\n",
    "lc_train = lc_total[mask_train] \n",
    "lc_test = lc_total[mask_test]\n",
    "\n",
    "df_label = pd.read_csv(\"../Datos/koi_metadata.csv\")\n",
    "df_label_train = df_label[mask_train] \n",
    "df_label_test = df_label[mask_test]\n",
    "#df_label_unlb =  df_label[mask_unlabeled]\n",
    "print(\"Read Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CenterScaler entrenado\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import IncrementalPCA,PCA,FastICA\n",
    "\n",
    "std = StandardScaler(with_mean=True,with_std=False) #with variance remove\n",
    "\n",
    "X_train = lc_train\n",
    "#fourier\n",
    "Xtrain_fourier = np.abs(np.fft.fft(X_train))\n",
    "std.fit(Xtrain_fourier)\n",
    "Xtrain_std = std.transform(Xtrain_fourier)\n",
    "print(\"CenterScaler entrenado\")\n",
    "\n",
    "X_test = lc_test\n",
    "#fourier\n",
    "Xtest_fourier = np.abs(np.fft.fft(X_test))\n",
    "Xtest_std = std.transform(Xtest_fourier)\n",
    "print(\"TEST escalado y fourier transformado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "---\n",
    "#### Generate 3 files in 3 dimension: 5, 10, 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA training with 5 features\n",
      "Generate CSV of koi_light_curves_PCA_train 5\n",
      "Generate CSV of koi_light_curves_PCA_test 5\n",
      "PCA training with 10 features\n",
      "Generate CSV of koi_light_curves_PCA_train 10\n",
      "Generate CSV of koi_light_curves_PCA_test 10\n",
      "PCA training with 25 features\n",
      "Generate CSV of koi_light_curves_PCA_train 25\n",
      "Generate CSV of koi_light_curves_PCA_test 25\n",
      "Process of dimensionality reduction completed\n",
      "CPU times: user 6min 35s, sys: 19.8 s, total: 6min 55s\n",
      "Wall time: 48.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dims= [5,10,25]\n",
    "\n",
    "for d in dims:\n",
    "    model = PCA(d)\n",
    "    \n",
    "    ##################### TRAIN #####################\n",
    "    model.fit(Xtrain_std)\n",
    "    print('PCA training with', d, 'features')\n",
    "\n",
    "    #################### ARRIBA ENTRENAMIENTO ###########\n",
    "    df = pd.DataFrame(model.transform(Xtrain_std),columns=[\"Component \"+str(t+1) for t in np.arange(d)])\n",
    "    df.to_csv(\"../Datos/PCA/koi_light_curves_FPCA_train\"+str(d)+\".csv\",index=False)\n",
    "    print('Generate CSV of koi_light_curves_PCA_train', d)\n",
    "    \n",
    "    ##################### TEST ########################\n",
    "    df = pd.DataFrame(model.transform(Xtest_std),columns=[\"Component \"+str(t+1) for t in np.arange(d)])\n",
    "    df.to_csv(\"../Datos/PCA/koi_light_curves_FPCA_test\"+str(d)+\".csv\",index=False)\n",
    "    print('Generate CSV of koi_light_curves_PCA_test', d)\n",
    "    \n",
    "print('Process of dimensionality reduction completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICA\n",
    "---\n",
    "#### Generate 3 files in 3 dimension: 5, 10 and 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.84627007,  0.84627007, -0.84627007, ..., -0.84627007,\n",
       "        -0.84627007,  0.84627007],\n",
       "       [-0.84627007,  0.84627007, -0.84627007, ..., -0.84627007,\n",
       "        -0.84627007,  0.84627007],\n",
       "       [-0.84627007,  0.84627007, -0.84627007, ..., -0.84627007,\n",
       "        -0.84627007,  0.84627007],\n",
       "       ..., \n",
       "       [-0.84627007,  0.84627007, -0.84627007, ..., -0.84627007,\n",
       "        -0.84627007,  0.84627007],\n",
       "       [ 1.18165588, -1.18165588,  1.18165588, ...,  1.18165588,\n",
       "         1.18165588, -1.18165588],\n",
       "       [-0.84627007,  0.84627007, -0.84627007, ..., -0.84627007,\n",
       "        -0.84627007,  0.84627007]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%time \n",
    "dims= [5,10,15]\n",
    "\n",
    "#Xtrain_std = np.nan_to_num(Xtrain_std)\n",
    "#Xtest_std = np.nan_to_num(Xtest_std)\n",
    "\n",
    "for d in dims:\n",
    "    model = FastICA(d,whiten=True)\n",
    "    \n",
    "    ##################### TRAIN #####################\n",
    "    model.fit(Xtrain_std) #opcion2 = Xtrain_fourier\n",
    "    print('ICA trainig with', d, 'features')\n",
    "\n",
    "    #################### ARRIBA ENTRENAMIENTO ###########\n",
    "    df = pd.DataFrame(model.transform(Xtrain_std),columns=[\"Component \"+str(t+1) for t in np.arange(d)])\n",
    "    df.to_csv(\"../Datos/ICA/koi_light_curves_FICA_train\"+str(d)+\".csv\",index=False)\n",
    "    print('Generate CSV Train', d)\n",
    "\n",
    "    ##################### TEST ########################\n",
    "    df = pd.DataFrame(model.transform(Xtest_std),columns=[\"Component \"+str(t+1) for t in np.arange(d)])\n",
    "    df.to_csv(\"../Datos/ICA/koi_light_curves_FICA_test\"+str(d)+\".csv\",index=False)\n",
    "    print('Generate CSV Test', d)\n",
    "    \n",
    "print('Process of dimensionality reduction completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OwnFATS\n",
    "---\n",
    "#### Generate Own FATS features of light curve (manualy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import FATS\n",
    "\n",
    "time_ex = np.arange(3000)\n",
    "magnitude_ex = np.random.rand(3000)\n",
    "\n",
    "lc_example = np.array([magnitude_ex, time_ex])\n",
    "\n",
    "time_start = time.time()\n",
    "#a = FATS.FeatureSpace(Data=['magnitude','time'],excludeList= ['SlottedA_length','PeriodLS','StetsonK_AC',\"Period_fit\",\"Psi_CS\",\"Psi_eta\"])\n",
    "#SACAR DE EXCLUDE PERIODLS\n",
    "a = a.calculateFeature(lc_example)\n",
    "print(\"Termino en %f segundos\"%(time.time()-time_start))\n",
    "a.result(method='dict')\n",
    "\n",
    "#it take too long!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def amplitude(magnitudes):\n",
    "    return 0.5 * (np.max(magnitudes) - np.min(magnitudes))\n",
    "\n",
    "def median_absolute_deviation(magnitudes):\n",
    "    median = np.median(magnitudes)\n",
    "    deviations = magnitudes - median\n",
    "    absolute_deviations = np.absolute(deviations)\n",
    "    return np.median(absolute_deviations)\n",
    "\n",
    "def residual_bright_faint_ratio(magnitudes):    # median as a fit\n",
    "    mean = np.mean(magnitudes)\n",
    "    brighter = magnitudes[magnitudes > mean]\n",
    "    fainter = magnitudes[magnitudes < mean]\n",
    "\n",
    "    resid_brighter = np.mean(np.square(brighter - mean))\n",
    "    resid_fainter = np.mean(np.square(fainter - mean))\n",
    "\n",
    "    ratio = resid_fainter / resid_brighter\n",
    "\n",
    "    return ratio\n",
    "\n",
    "def own_fats(sequence):\n",
    "    time_ex =  np.arange(len(sequence))\n",
    "\n",
    "    minim=np.min(sequence)\n",
    "    maxim = np.max(sequence)\n",
    "    mean = np.mean(sequence)\n",
    "    std = np.std(sequence)\n",
    "    iqr = stats.iqr(sequence) #q31\n",
    "    skew = stats.skew(sequence)\n",
    "    kurt = stats.kurtosis(sequence)\n",
    "    q1 = np.percentile(sequence, 25)\n",
    "    q2 = np.percentile(sequence, 50)\n",
    "    model = LinearRegression(normalize=True,n_jobs=-1)\n",
    "    model.fit(time_ex.reshape(-1,1),sequence)\n",
    "    slope = model.coef_[0]\n",
    "    #new features\n",
    "    ampl = amplitude(sequence)\n",
    "    mad = median_absolute_deviation(sequence)\n",
    "    br_fa = residual_bright_faint_ratio(sequence)\n",
    "    median = np.median(sequence)\n",
    "    return np.array([minim,maxim,mean,std,iqr,skew,kurt,q1,q2,slope,ampl,mad,br_fa,median])\n",
    "\n",
    "def metadata_columns(match,array):\n",
    "    df = pd.read_csv(\"../Datos/koi_metadata.csv\")\n",
    "    metadata = df[(df[\"KOI Name\"] == match)].values[0][3:]\n",
    "    return np.hstack((array,metadata))\n",
    "\n",
    "columns_FATS = [\"Minimum\",\"Maximum\",\"Mean\",\"Std\",\"IQR\",\"Skew\",\"Kurtosis\",\"Q1\",\"Q2\",\"Slope\",\"Amplitude\",\"MAD\",\n",
    "               \"Residual Bright Faint Ratio\",\"Median\"]\n",
    "aux = pd.read_csv(\"../Datos/koi_metadata.csv\")\n",
    "columns_metadata = list(aux.columns[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import resample\n",
    "\n",
    "def extract_FATS(X,df_label):\n",
    "    X_fats = []\n",
    "    for sequence,match in zip(X,df_label[\"KOI Name\"]):\n",
    "        aux = own_fats(sequence)\n",
    "        final = metadata_columns(match,aux)\n",
    "        X_fats.append(final)\n",
    "    return np.asarray(X_fats)\n",
    "\n",
    "def save(name_set,features,df_label):\n",
    "    df2save = pd.DataFrame(features,columns=columns_FATS+columns_metadata)\n",
    "    df2save[\"KOI Name\"] = df_label[\"KOI Name\"]\n",
    "    df2save.to_csv(\"../Datos/OwnFats/koi_light_curves_FATS2_metadata_\"+name_set+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training already extracted\n",
      "Validation already extracted\n"
     ]
    }
   ],
   "source": [
    "%time features = extract_FATS(lc_train,df_label_train) #train\n",
    "save(\"train_model\",features,df_label_train)\n",
    "print(\"Training already extracted\")\n",
    "\n",
    "%time features = extract_FATS(lc_test,df_label_test) #test\n",
    "save(\"test_model\",features,df_label_test)\n",
    "print(\"Validation already extracted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
